{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample\n",
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from llama_index.core import ServiceContext, VectorStoreIndex\n",
    "from llama_index.core.schema import TextNode\n",
    "# from llama_index.embeddings import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queries: Dict[str, str],  # qid => query\n",
    "## corpus: Dict[str, str],  # cid => doc\n",
    "## relevant_docs: Dict[str, Set[str]],  # qid => Set[cid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-small-en\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = './data/train_dataset.json'\n",
    "VAL_DATASET_FPATH = './data/val_dataset.json'\n",
    "\n",
    "# We use a very small batchsize to run this toy example on a local machine. \n",
    "# This should typically be much larger. \n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "examples = []\n",
    "for query_id, query in queries.items():\n",
    "    node_id = relevant_docs[query_id][0]\n",
    "    text = corpus[node_id]\n",
    "    example = InputExample(texts=[query, text])\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='exp_finetune',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator, \n",
    "    evaluation_steps=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmtesting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
